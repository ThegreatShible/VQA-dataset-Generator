{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d0PODRd38MQR"
   },
   "source": [
    "# Filtering questions from VQA dataset\n",
    "This notebook aims to filter questions from the VQA dataset corresponding to a specific domain. This is done by domain related keyword search on questions. The keywords are provided in a text file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8duxm7uZ8-g1"
   },
   "source": [
    "## Variables\n",
    "This section contains the variable used in this notebook, the variables must change to an environment to another so that the program can run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tszZPq_P9MRP"
   },
   "outputs": [],
   "source": [
    "# To Implement\n",
    "    #this variable represents the path to the imported drive in the notebook, if you don't import drive, ignore this variable \n",
    "drive_home = ''\n",
    "    #root directory \n",
    "root_directory =  ''\n",
    "\n",
    "\n",
    "VQA_data_root = os.path.join(root_directory, 'VQA')\n",
    "results_directory = os.path.join(root_directory, 'results/VQA')\n",
    "\n",
    "#path representing the file of train questions from VQA dataset \n",
    "train_questions_path = os.path.join(VQA_data_root, 'v2_OpenEnded_mscoco_train2014_questions.json')\n",
    "#path to the file containing the keywords to filter the questions\n",
    "key_words_path = os.path.join(root_directory, 'keywords_files/indoor.txt')\n",
    "#path_where to save the filtered tuples (questions ids , questions and images ids) of train questions\n",
    "train_save_path = os.path.join(results_directory, 'train_VQA_filteredImages.txt')\n",
    "train_annotation_save_path = os.path.join(results_directory,'/annotations.json')\n",
    "#train_answers_path is the file where are located VQA V2 train annotations\n",
    "train_answers_path = os.path.join(VQA_data_root, 'v2_mscoco_train2014_annotations.json')\n",
    "#path representing the place of questions from VQA dataset (copied from val_download_path and pasted on this path)\n",
    "val_questions_path = os.path.join(VQA_data_root, 'v2_mscoco_val2014_questions.json')\n",
    "#path_where to save the filtered tuples (questions ids , questions and images ids) of val questions\n",
    "val_save_path = os.path.join(results_directory,'val_VQA_filteredImages.txt')\n",
    "val_annotation_save_path = os.path.join(results_directory,'val_annotations.json')\n",
    "val_answers_path = os.path.join(VQA_data_root, 'v2_mscoco_val2014_annotations.json')\n",
    "final_val_file = os.path.join(results_directory,'final_val.csv')\n",
    "final_train_file = os.path.join(results_directory,'final_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zOyp_F9V83cU"
   },
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6a7pKBYUAZ3x"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#remove if you don't use drive\n",
    "from google.colab import drive\n",
    "import shutil\n",
    "import json\n",
    "from itertools import groupby\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g3XHzD0iBrW_"
   },
   "source": [
    "## Mount drive (remove line if you don't) and download train questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TS0R7w9eB19w"
   },
   "source": [
    "### mount drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "glhBEspUqXye"
   },
   "outputs": [],
   "source": [
    "#remove if you don't use drive\n",
    "drive.mount(drive_home)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l7qGrRvtCclR"
   },
   "source": [
    "## Load train questions\n",
    "The questions file is a bunch of lines containing the question id, the question and the image id related to the question in the VQA dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xnbzOO-bsqje"
   },
   "outputs": [],
   "source": [
    "f = open(train_questions_path)\n",
    "q = json.load(f)\n",
    "questionsIds = [(question['question_id'], question['question'], question['image_id']) for question in q['questions']]\n",
    "f.close\n",
    "questionsIds[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9LIjtXHmub_i"
   },
   "outputs": [],
   "source": [
    "questions = [x[1] for x in questionsIds]\n",
    "questions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tu5WytK_Czrv"
   },
   "source": [
    "## filter questions\n",
    "Filter the questions by keywords, we get from this methods only the questions containing at least on of the keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rgkTpIQoEO6j"
   },
   "source": [
    "### filterQuestions function to filter questions by keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MOp7lUkFuoqK"
   },
   "outputs": [],
   "source": [
    "# filter questions and get the ones containing at least on keyword from key_words\n",
    "def filterQuestions(questions, key_words):\n",
    "  def contains(question, key_words):\n",
    "    if not key_words:\n",
    "      return False\n",
    "    else :\n",
    "      return (key_words[0] in question) or contains(question, key_words[1:])\n",
    "\n",
    "  return [x for x in questions if contains(x[1], key_words)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XyHDQkUy7ssN"
   },
   "source": [
    "### get images ids with questions that have at least one questions in filtered questions\n",
    "This is to catch all questions that have relation to indoor, with filterQuestions we got all questions containing keywords, that means that images filtered are indoor images (most of them) and that the other questions that don't have keywords in that images could also be indoor questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DyV22kLp7s4p"
   },
   "outputs": [],
   "source": [
    "def get_filtered_images(questions_ids, questions_image):\n",
    "  return [x for x in questions_image if x[0] in questions_ids]\n",
    "\n",
    "def save_csv(save_file, data):\n",
    "  with open(save_file, 'w') as f : \n",
    "    writer = csv.writer(f)\n",
    "    for d in data : \n",
    "      writer.writerow(d)\n",
    "      \n",
    "      \n",
    "def read_csv(file) : \n",
    "  with open(file, 'r') as f : \n",
    "    reader = csv.reader(f)\n",
    "    data = [x for x in reader]\n",
    "  return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8hwpR_L8EHtr"
   },
   "source": [
    "### treat keywords\n",
    "Treating keywods such as making them lowercase, removing extra-space ... and the loading them\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o0ZHBt4cw3bx"
   },
   "outputs": [],
   "source": [
    "f = open(key_words_path,'r')\n",
    "key_words = f.readlines()\n",
    "f.close\n",
    "treated_key_words = [x.strip().lower() for x in key_words if x.strip() != ''] \n",
    "  \n",
    "treated_key_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_8uFCgJE6x4"
   },
   "source": [
    "### filter questions \n",
    "The result of applying the filter to questions is a tuple containing (question_id, question, image_id) where question contains of the keywords in key_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PATNFM5h3TQa"
   },
   "outputs": [],
   "source": [
    "train_filtred_questions = filterQuestions(questionsIds, treated_key_words)\n",
    "t = train_filtred_questions\n",
    "(q_id, q, im) = zip(*train_filtred_questions)\n",
    "train_filtred_questions =get_filtered_images(q_id,questionsIds)\n",
    "train_filtred_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TY9XovW1HZV6"
   },
   "outputs": [],
   "source": [
    "ques = set([x[2] for x in train_filtred_questions])\n",
    "with open(train_questions_path) as f :\n",
    "    q = json.load(f)\n",
    "questionsIds = [(question['question_id'], question['question'], question['image_id']) for question in q['questions'] if question['image_id'] in ques]\n",
    "len(questionsIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nITzPHyA6YI3"
   },
   "outputs": [],
   "source": [
    "len(list(set([x[2] for x in train_filtred_questions])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JA4zGw2JfL31"
   },
   "outputs": [],
   "source": [
    "with open(train_answers_path) as f :\n",
    "    anno = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GjUJ1bC4kqWf"
   },
   "outputs": [],
   "source": [
    "annotations = [x for x in anno['annotations']]\n",
    "fq_id, fq, f_im_id = zip(*train_filtred_questions)\n",
    "qid_ans = dict([(x[\"question_id\"], [y['answer'] for y in x['answers']]) for x in annotations])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tkmyuNmlsBEW"
   },
   "outputs": [],
   "source": [
    "final_train_dataset = []\n",
    "for q_id, q, im in  train_filtred_questions :\n",
    "  if q_id in qid_ans : \n",
    "    final_train_dataset.append((im, q, qid_ans[q_id]))\n",
    "#filtered_annotations = [x for x in annotations if str(x['image_id']) in f_im_id]\n",
    "save_csv(final_train_file, final_train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u5kmghjMGH5S"
   },
   "source": [
    "## save tuples of filtred questions\n",
    "\n",
    "One line of the saved file is in the format :  question_id,question,image_id\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jSY88n2KETAk"
   },
   "outputs": [],
   "source": [
    "def save(path, filtred_questions):\n",
    "  f = open(path, 'w')\n",
    "  for i,x in enumerate(filtred_questions):\n",
    "    if i != 0 : \n",
    "      f.write('\\n')\n",
    "    f.write(str(x[0]) +';'+str(x[1]) +';'+str(x[2]))\n",
    "  f.close\n",
    "save(train_save_path,train_filtred_questions )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mmfaYdtWJh1Q"
   },
   "source": [
    "## Load val questions (tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LLUMsblBIurK",
    "outputId": "8d3a20d8-cb73-47c9-9155-d1b9f6002bea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(val_questions_path)\n",
    "q = json.load(f)\n",
    "questionsIdsVal = [(question['question_id'], question['question'], question['image_id']) for question in q['questions']]\n",
    "f.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xlTpGGSzJoST"
   },
   "source": [
    "## Filter val questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dfGb_oVII8Af"
   },
   "outputs": [],
   "source": [
    "val_filtred_questions = filterQuestions(questionsIdsVal, treated_key_words)\n",
    "(q_id, q, im) = zip(*val_filtred_questions)\n",
    "val_filtred_questions =get_filtered_images(q_id,questionsIdsVal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y6TzXkZGJux1"
   },
   "outputs": [],
   "source": [
    "with open(val_answers_path) as f :\n",
    "  anno = json.load(f)\n",
    "\n",
    "  \n",
    "annotations = [x for x in anno['annotations']]\n",
    "fq_id, fq, f_im_id = zip(*val_filtred_questions)\n",
    "qid_ans = dict([(x[\"question_id\"], [y['answer'] for y in x['answers']]) for x in annotations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8S3Ny3iWrxt"
   },
   "outputs": [],
   "source": [
    "final_val_dataset = []\n",
    "for q_id, q, im in  val_filtred_questions :\n",
    "  if q_id in qid_ans : \n",
    "    final_val_dataset.append((im, q, qid_ans[q_id]))\n",
    "#filtered_annotations = [x for x in annotations if str(x['image_id']) in f_im_id]\n",
    "save_csv(final_val_file, final_val_dataset)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "VQA2 Dataset",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
