{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PNdnvTNXLY_j"
   },
   "source": [
    "# Visual Genome quesiton generation\n",
    "This notebooks aims to filter Visual Genome data to get only specific domain data. The Visual Genome dataset contains objects annotations that we will use to filter our data. The result is images containing objects listed in keywords text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nnNZF7deMEjZ"
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HUK30zzzNDfV"
   },
   "outputs": [],
   "source": [
    "#import drive, you can work without drive\n",
    "\n",
    "from google.colab import drive\n",
    "#from visual_genome import api\n",
    "import json\n",
    "import seaborn as sbs\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "from collections import Counter\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "#from gensim.models import Word2Vec\n",
    "#import gensim\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NA0nFaQjMIR0"
   },
   "source": [
    "## variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AbM5AROAM597"
   },
   "outputs": [],
   "source": [
    "#mounting drive path, this is optional\n",
    "drive_path = '/content/gdrive'\n",
    "#file containing keywords for filtering images\n",
    "keywords_file = '/content/gdrive/My Drive/Colab/indoors.txt'\n",
    "#file containing negative keywords for filtering images\n",
    "neg_keywords_file = '/content/gdrive/My Drive/Colab/Nindoor.txt'\n",
    "#download_objects.json\n",
    "download_objects_path = '/content'\n",
    "#file where to save image ids\n",
    "writingPath = '/content/gdrive/My Drive/Colab/VisualGenomeImageIds.txt'\n",
    "#Download QAs path\n",
    "download_QAs_path = '/content'\n",
    "#file where to save Questions Answers TODO\n",
    "save_qas_file = '/content/gdrive/My Drive/Colab/QAs.json'\n",
    "#TODO : file where to download GQA questions\n",
    "download_GQA_questions = '/content/gdrive/My Drive/Colab/visual_genome/GQA_QAs'\n",
    "#TODO :\n",
    "save_GQA = '/content/gdrive/My Drive/Colab/results/visual_genome/GQA.csv'\n",
    "filtred_GQA = '/content/gdrive/My Drive/Colab/results/visual_genome/GQA_filtered.csv'\n",
    "visual_genome_path = '/content/gdrive/My Drive/Colab/visual_genome'\n",
    "VG_GQA = '/content/gdrive/My Drive/Colab/results/visual_genome/VG_GQA.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ysV2fK8POUh7"
   },
   "source": [
    "## Mounting Drive (Don't do it if you don't use drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ggvfEnf_OUuS"
   },
   "outputs": [],
   "source": [
    "drive.mount(drive_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D-4Qx18fMMkW"
   },
   "source": [
    "## Visual Genome API\n",
    "Install a python Visual Genome API that let us interact with The Visual Genome dataset like getting objects in an image...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J63Aq8DTOl6J"
   },
   "source": [
    "\n",
    "### Download all image Ids\n",
    "Download them via API and count them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BjjSOEAyM7ea"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "qas = api.get_QA_of_image(id=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5PULAvlJO0Ni"
   },
   "source": [
    "## Loading and filtering keywords file\n",
    "Remove extra-characters, empty strings and repeated words from keywords. Keywords are name of objects that must be present in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sKKa3u9sSWs8"
   },
   "outputs": [],
   "source": [
    "f = open(keywords_file, 'r')\n",
    "lines = f.readlines()\n",
    "lines = [x.lower().strip() for x in lines if x.lower().strip() != '']\n",
    "#remove repeated\n",
    "lines = list(set(lines))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oFXDCYtATNs3"
   },
   "outputs": [],
   "source": [
    "g = open(neg_keywords_file, 'r')\n",
    "Nlines = g.readlines()\n",
    "Nlines = [x.lower().strip() for x in Nlines if x.lower().strip() != '']\n",
    "#remove repeated\n",
    "Nlines = list(set(Nlines))\n",
    "g.close()\n",
    "Nlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PWV_moZcSv39"
   },
   "source": [
    "## Download objects \n",
    "Download objects present in the Visual Genome dataset. The file contains the graph scene of each image in Visual Genome. Each graph scene contains a list of objects and other informations.\n",
    "idGraph will contain tupples of (image id, objects present in this image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UR9C65WtB6qo"
   },
   "outputs": [],
   "source": [
    "# put objects.json in drive\n",
    "!wget -P '$download_objects_path' http://visualgenome.org/static/data/dataset/objects.json.zip\n",
    "os.chdir(download_objects_path)\n",
    "!unzip objects.json\n",
    "json_path = os.path.join(download_objects_path, 'objects.json')\n",
    "f = open(json_path,'r')\n",
    "idGraphs= json.load(f)\n",
    "f.close()\n",
    "idGraph = []\n",
    "for g in idGraphs:\n",
    "  objs = []\n",
    "  for obj in g['objects']:\n",
    "    for name in obj['names']:\n",
    "      objs.append(name)\n",
    "  idGraph.append((g['image_id'],objs))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JXY9pfVCTxd9"
   },
   "source": [
    "### copying idGraph in idObjs (this could be avoided but i don't want to refactor code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ujdOozvkDsdn"
   },
   "outputs": [],
   "source": [
    "idObjs = [(id, objects) for (id, objects) in idGraph]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KjoUebuDUizd"
   },
   "outputs": [],
   "source": [
    "Nlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LXVYRWoXULCv"
   },
   "source": [
    "## Filter objects\n",
    "Here, we filter objects present in visual genome, we get the objects that are in 'lines' (keywords) and that are not in 'Nlines' (negative keywords).\n",
    "idObjsLen is a list of tuples of (image id , list of objects, length of the list of objects). The tuples represent the images that have at least on object that passed the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0hDBQHMiEQIY"
   },
   "outputs": [],
   "source": [
    "idObjsLen = []\n",
    "for (id, objs) in idObjs:\n",
    "  objs1 = [obj.lower().strip() for obj in objs]\n",
    "  s = set(objs1).intersection(lines)\n",
    "  s2 = set(objs1).intersection(Nlines)\n",
    "  if (not len(s) == 0) and (len(s2) == 0):\n",
    "    idObjsLen.append((id, objs,len(s)))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pV-WgmEFhHik"
   },
   "outputs": [],
   "source": [
    "len(idObjsLen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J4_e5utKb5aV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "objects = [x  for y in idObjsLen for x in y[1]]\n",
    "df = pd.Series(objects).value_counts()\n",
    "df = df.sort_values(ascending =False).head(30)\n",
    "df.to_csv('/content/df.csv', \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kPPy0dnsVyev"
   },
   "source": [
    "### occurences of objects in filtered images\n",
    "idObjLen2 is idObjLen sorted by list of objects length, this was done in my case to fill the keyword file with new keywords based when i see some words that has high occurence needed for better filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TniN0-oUil07"
   },
   "outputs": [],
   "source": [
    "idObjsLen2 = sorted(idObjsLen, key=lambda tup: tup[2],reverse = True)\n",
    "#idObjsLen2 = [ i  for i in idObjsLen if i[2] == 1]\n",
    "idObjsLen2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iHEzNeO_lroo"
   },
   "outputs": [],
   "source": [
    "\n",
    "occurences = [ i[2]  for i in idObjsLen if i[2] >= 0]\n",
    "d = pd.Series(occurences)\n",
    "d.value_counts().plot(kind='pie')\n",
    "#sbs.distplot(occurences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LwyR2frRWte2"
   },
   "source": [
    "### occurences of remaining words\n",
    "This was used to fill negative keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gr-e_MkET8Kh"
   },
   "outputs": [],
   "source": [
    "\n",
    "ObjsP = [x[1] for x in idObjsLen]\n",
    "ObjsP = [y for x in ObjsP for y in x if y not in lines]\n",
    "FObjsP = Counter(ObjsP).most_common()\n",
    "FObjsP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ouNXxaZiXVkU"
   },
   "source": [
    "## Save filtered images in file\n",
    "We will save in the filtered images IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xrUnneRGmk-G"
   },
   "outputs": [],
   "source": [
    "\n",
    "imageIDs = [x[0] for x in idObjsLen2]\n",
    "l  = open(writingPath,'w')\n",
    "for i,x in enumerate(imageIDs):\n",
    "  if i != 0 : \n",
    "    l.write('\\n')\n",
    "  l.write(str(x))\n",
    "l.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SVAt42vaCl89"
   },
   "source": [
    "## Get QA and save them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mnHYGLatTnrF"
   },
   "source": [
    "### download visual genome questions answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_jy9M3gQ76i4"
   },
   "outputs": [],
   "source": [
    "!wget -P '$download_QAs_path' http://visualgenome.org/static/data/dataset/question_answers.json.zip\n",
    "os.chdir(download_QAs_path)\n",
    "!unzip question_answers.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v5wJ2IZcINlV"
   },
   "source": [
    "### Filter questions answers\n",
    "We take questions answers that correspond to filtered images. We save that in a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V-IiBOtjCiQu"
   },
   "outputs": [],
   "source": [
    "with open(writingPath) as p : \n",
    "  imageIDs = [int(x.strip()) for x in p.readlines() if x != '']\n",
    "  \n",
    "Int_imageIDs = [int(x) for x in imageIDs]\n",
    "QAs_path = os.path.join(download_QAs_path, 'question_answers.json')\n",
    "with open(QAs_path, 'r') as g : \n",
    "  QAs = json.load(g)\n",
    "i = 0\n",
    "for x in QAs : \n",
    "  if i == 10:\n",
    "    break\n",
    "  print(x)\n",
    "  i +=1\n",
    "objs = []\n",
    "count = 0\n",
    "for im in QAs : \n",
    "  image_id = im['id']\n",
    "  qas = im['qas']\n",
    "  \n",
    "  if image_id in Int_imageIDs:\n",
    "    count +=1\n",
    "    filtered_QAs = [{'question' : x['question'], 'answer' : x['answer']} for x in qas ]\n",
    "    obj = {\n",
    "      'image_id' : image_id,\n",
    "      'QAs' : filtered_QAs\n",
    "    }\n",
    "    objs.append(obj)\n",
    "print(count)\n",
    "with open(save_qas_file , 'w') as f : \n",
    "   json.dump(objs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lP98SFrGH5vQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "QAs_path = os.path.join(download_QAs_path, 'question_answers.json')\n",
    "with open(QAs_path, 'r') as g : \n",
    "  QAs = json.load(g)\n",
    "i = 0\n",
    "\n",
    "objs = []\n",
    "\n",
    "for im in QAs :\n",
    "  if im['id'] == 4 : \n",
    "  \n",
    "    qas = im['qas']\n",
    "    for qa in qas : \n",
    "      objs.append((qa['question'], qa['answer']))\n",
    "    break\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nKl02BnoreaQ"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'questions': [x[0] for x in objs], 'reponses': [x[1] for x in objs]})  \n",
    "df.to_csv('/content/df.csv', ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9TBOXtoUKUAc"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#!pip install gensim\n",
    "#os.chdir('/content/gdrive/My Drive/Colab')\n",
    "#!gunzip -f -k GoogleNews-vectors-negative300.bin.gz\n",
    "\n",
    "#os.chdir('/content')\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('/content/gdrive/My Drive/Colab/GoogleNews-vectors-negative300.bin', binary = True)\n",
    "sim = []\n",
    "out = []\n",
    "for word in lines:\n",
    "  for objs in idObjs:\n",
    "    for obj in objs[1]:\n",
    "      if (obj in model.wv.vocab) and (word in model.wv.vocab):\n",
    "        sim.append((obj, model.similarity(obj, word)))\n",
    "      else:\n",
    "        if not obj in model.wv.vocab : \n",
    "          out.append((objs[0],obj))\n",
    "sim = sim.sort(key=lambda tup: tup[1])    \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4d3gmC6mID9S"
   },
   "source": [
    "# QAs from GQA\n",
    "GQA is a new dicipline that aims to enhance visual reasoning on VQA. There is a GQA dataset using visual genome in https://cs.stanford.edu/people/dorarad/gqa/download.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EalQkbSJIYHd"
   },
   "source": [
    "## Download Questions from GQA dataset\n",
    "Downlaod questions and load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TxKZPWDfItmt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(download_GQA_questions)\n",
    "#!wget \"$download_GQA_questions\" \"https://s3-us-west-1.amazonaws.com/gqa/questions.zip\"\n",
    "#!unzip questions.zip\n",
    "train_questions_GQA = os.path.join(download_GQA_questions, 'train_all_questions')\n",
    "val_questions_GQA = os.path.join(download_GQA_questions, 'val_all_questions.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y4SH0DJsXPJh"
   },
   "outputs": [],
   "source": [
    "def readGQA(path_file):\n",
    "  with open(path_file,'r') as f:\n",
    "    qes = json.load(f)\n",
    "  return ([(x['imageId'], x['question'], x['answer']) for x in qes.values()])\n",
    " \n",
    "ques_path= [os.path.join(train_questions_GQA,x) for x in os.listdir(train_questions_GQA)]\n",
    "\n",
    "with open(save_GQA, 'a') as f:\n",
    "  writer = csv.writer(f)\n",
    "  for file in ques_path : \n",
    "    data = readGQA(file)\n",
    "    for i,d in enumerate(data) : \n",
    "      writer.writerow(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RJLlooXrVVh9"
   },
   "outputs": [],
   "source": [
    "with open(save_GQA, 'r') as f : \n",
    "  reader = csv.reader(f)\n",
    "  data = [x for x in reader]\n",
    "len(data)\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rttZxpx5Jf3l"
   },
   "source": [
    "## Filter questions and save them\n",
    "We filter questions by searching for image id that are common in the image ids filtered before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yhndPvLzJd9b"
   },
   "outputs": [],
   "source": [
    "def get_imageIDs(): \n",
    "  with open(save_qas_file) as f : \n",
    "    data = json.load(f)\n",
    "  return set([int(x['image_id']) for x in data])\n",
    "\n",
    "def read_csv(file) : \n",
    "  with open(file, 'r') as f : \n",
    "    reader = csv.reader(f)\n",
    "    data = [x for x in reader]\n",
    "  return data\n",
    "  \n",
    "'''with open(writingPath) as p : \n",
    "  int_imagesIDs = set([int(x.strip()) for x in p.readlines() if x != ''])'''\n",
    "\n",
    "def get_filtered_questions_answers(qas_file, int_imagesIDs ):\n",
    "  qas = read_csv(qas_file)\n",
    "  return [(x[0], x[1], x[2]) for x in qas if int(x[0]) in int_imagesIDs]\n",
    "ids =  get_imageIDs()\n",
    "print('got ids')\n",
    "GQA_qas = get_filtered_questions_answers(save_GQA, ids)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fCLP4n2-y7tk"
   },
   "outputs": [],
   "source": [
    "with open(filtred_GQA, 'w') as f : \n",
    "  writer = csv.writer(f)\n",
    "  for x in GQA_qas : \n",
    "     writer.writerow(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hVXcpq_VMc6V"
   },
   "source": [
    "# Fusion GQA and Visual Genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TOSOXTF--XS5"
   },
   "outputs": [],
   "source": [
    "def get_VG(file_path): \n",
    "  with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "  return [[y['image_id'],x['question'],x['answer']] for y in data for x in y['QAs']]\n",
    "\n",
    "VG = get_VG(save_qas_file)\n",
    "GQA = read_csv(filtred_GQA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CtmUWkoZ-AOi"
   },
   "outputs": [],
   "source": [
    "with open(VG_GQA, 'w') as f :\n",
    "  writer = csv.writer(f)  \n",
    "  for x in VG:\n",
    "    writer.writerow(x)\n",
    "  for x in GQA : \n",
    "    writer.writerow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T4YEN5PnzX0V"
   },
   "outputs": [],
   "source": [
    "for i,x in enumerate(sorted(list(GQA))) :\n",
    "  if i == 10 :\n",
    "    break\n",
    "  print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2NjzovBrWJ1T"
   },
   "source": [
    "# Fusion of all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3koc3-M1JXuC"
   },
   "outputs": [],
   "source": [
    "def readVG(file) :\n",
    "  with open(file, 'r') as f: \n",
    "    data = json.load(f)\n",
    "  return data\n",
    "\n",
    "def readVQA():\n",
    "  return \n",
    "def fusion(dic1, dic2)\n",
    "  return (dic1,dic2)\n",
    "def split(dic1, dic2, dic3) : \n",
    "  return(train, test)\n",
    "\n",
    "#format must be id -> infos\n",
    "def readVQA(file): \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rr2OnJEwLZhw"
   },
   "outputs": [],
   "source": [
    "print(len(ids1.intersection(train_ids)))\n",
    "print(len(ids1.intersection(val_ids)))\n",
    "print(len(train_ids))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "visualGenome.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
